# データの分類と予測と機械学習

## 1. データの活用法について

- データマイニングとは、大量のデータを調べて、そこから勝ちのある情報を抽出すること
- データマイニングの基本は「予測」「分類」「関連」

__データマイニングの手順__

1. 対象データを収集
2. 形態素解析などしてデータを分割
3. データをクリーニング（外れ値、欠損値、ノイズ除去）
4. データを要約（次元縮約、属性選択など）
5. データマイニング（統計や他のデータと組み合わせるなど）
6. 評価と検証


__代表的なデータマイニング法__

1. 相関ルール: Xが起きるとにはYも起きやすい
2. 回帰分析: Xの属性から、数値変数Yを予測
3. クラス分類: Xの属性から、そのクラスCを予測
4. クラスタリング: 似ているもの同士をまとめる


2. ベイジアンフィルタによる分類

- [ベイジアンフィルタ - Wikipedia](https://ja.wikipedia.org/wiki/%E3%83%99%E3%82%A4%E3%82%B8%E3%82%A2%E3%83%B3%E3%83%95%E3%82%A3%E3%83%AB%E3%82%BF)


### ナイーブベイズ分類のアルゴリズム

__ベイズの定理__

```mathematica
P(Y|X) = P(Y)P(X|Y) / P(X)
```

迷惑メールの分類に例えると

```mathematica
P(スパム|メールの特徴F) = P(スパム) × P(メールの特徴F|スパム) / P(メールの特徴F)
```

- P(スパム) は、あるメールがスパムである確率（メールの特徴Fを観察する前の確率を表しているため、事前確率）
- P(スパム|メールの特徴F) は、あるメールの特徴Fを見たとき、そのメールがスパムである確率
- P(メールの特徴F|スパム) は、スパムにメールの特徴Fが現れる確率
- P(メールの特徴F) は、スパムメールを含むすべてのメールの中で、メールの特徴Fを持ったメールが出現する確率


__ナイーブベイズ分類について__

```mathematica
X = 入力テキスト
Y = 決定されるカテゴリー

# ベイズ定理の分母である P(X) は入力テキストが与えられる確率となりますが、
# どのカテゴリーでも同じ値になると考えて、考慮しないことにすると

P(Y|X) = P(Y)P(X|Y)
# となる

# ここで、入力テキストである X を書く単語 x の集合と考えると、
# 次の式に直すことができる
P(X|Y) = P(x1|Y) P(x2|Y) P(x3|Y) ...P(xN|Y)

# すると、P(xN|Y) の確率は、分割した単語があるカテゴリーに属する確率を求めることになり
# あるカテゴリーにその単語が出現した確率を求めます

単語の出現確率 = 単語の出現回数 / カテゴリーの全単語数
```

### Node.js でベイジアンフィルタを使う



## 3. 移動平均を利用した予測とグラフの描画

### 需要予測について

- 予測はあくまでも予測なので現実にはその通りにはならない
- 利用する際には、予測の誤差を考慮する必要がある
- 最も広く利用されているのは、[移動平均法](https://www.google.co.jp/url?sa=t&rct=j&q=&esrc=s&source=web&cd=4&cad=rja&uact=8&ved=0CDAQFjADahUKEwirwamb9M3IAhWJpJQKHf8UAo8&url=https%3A%2F%2Fja.wikipedia.org%2Fwiki%2F%25E7%25A7%25BB%25E5%258B%2595%25E5%25B9%25B3%25E5%259D%2587&usg=AFQjCNEUXWcf87-pDd_MFag0FIBjWpBr8g&sig2=3cGzaTAZFQ7LwIGGbUewuA)と[指数平滑法](https://ja.wikipedia.org/wiki/%E7%A7%BB%E5%8B%95%E5%B9%B3%E5%9D%87#.E6.8C.87.E6.95.B0.E7.A7.BB.E5.8B.95.E5.B9.B3.E5.9D.87)


### 単純移動平均について

```mathematica
       Pm + Pm-1 + Pm-2 + Pm-3
SMAm = ------------------------
                  n
```

### 指数平滑法について

```mathematica
予測値 = α × 前回実績値 + (1 - α) × 前回予測値 = 前回予測値 + α × (前回実績値 - 前回予測値)

# 平滑化定数 α の値
α = 2 ÷ (N + 1)
# とする他に
α = 1 ÷ N
# と計算するものもある
```

### 明日の平均気温を予測する

## 4. 人工無能と会話しよう

## 5. サポートベクターマシンで文字認識しよう (前編)

__サポートベクターマシンとは?__

- Support Vector Machine; SVM
- 1995年に統計的学習理論の枠組みで提案された学習機械で、特にパターン認識能力に優れている
- マージン最大化という方針を採用して識別平面を決定する


### 文字認識に挑戦

- [THE MNIST DATABASE](http://yann.lecun.com/exdb/mnist/)
  大量の手書き数字データを公開しているWebサイト

#### SVM で学習モデルを作るまでのシナリオ

1. パターンを学習させる
2. 学習データに基づいて手書き文字を判定させる

__手書き数字のデータベースから、パターン学習させる手順__

1. MNISTの手書き数字をダウンロード
2. データを、扱いやすいように、CSV ファイルに変換
3. CSV ファイルを元に、学習データ (.svm) を作成する
4. 学習データをSVMに学習させ、モデル (.model) を作成する


## 6. サポートベクターマシンで文字認識しよう (後編)
